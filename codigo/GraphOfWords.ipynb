{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keywords\n",
    "## En este notebook se definen cuatro funciones esenciales:\n",
    "### (1) graph_weighted(text,K,filter_nouns_adj,digraph) que recibe un texto en forma de string (text), el tamano de la ventana de co-ocurrencia en forma de entero (K), la decision si filtrar NOUNs y ADJs en forma de BOOL (filter_nouns_adj) y la decision de usar grafo dirigido en forma de BOOL (digraph). Esta funcion entrega el grafo de ocurrencia asociado a un texto. \n",
    "### (2) keywords_pagerank(text,number_keywords,filter_nouns_adj,K,digraph) que recibe ademas de las mismas variables que (1) el numero de keywords (number_keywords). Esta funcion entrega un conjunto de keywords asociado a un texto. \n",
    "### (3) keywords_kcore(text,filter_nouns_adj,K,digraph) que recibe las mismas variables que (1) y entrega los nodos de main core del grafo como una manera de representar los keywords. \n",
    "### (4) bigram_keywords(text,filter_nouns_adj,K,digraph) que recibe idem que (1) y entrega un conjunto de 2-gramas de keywords ordenados segun frecuencia de aparicion en el texto (mayor a menor). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import spacy\n",
    "import operator\n",
    "nlp = spacy.load('en')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize\n",
    "import re\n",
    "import string\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0) funcion que limpia los textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text,filter_nouns_adj):\n",
    "    text=re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "    sentences=sent_tokenize(text)\n",
    "    sentences=[nlp(sentence) for sentence in sentences]\n",
    "    if filter_nouns_adj==True:\n",
    "        sentences=[[token.lemma_ for token in sentence if token.tag_=='NN' or token.tag_=='NNS' or token.tag_=='JJ' or token.pos_=='PROPN'] for sentence in sentences]\n",
    "    else:\n",
    "        sentences=[[token.lemma_ for token in sentence] for sentence in sentences]\n",
    "\n",
    "    text=[item for sublist in sentences for item in sublist]\n",
    "    text=[word for word in text if not word in stop_words]\n",
    "    table=str.maketrans('', '', string.punctuation)\n",
    "    text = [w.translate(table) for w in text] ## removemos los simbolos que funcionan como sustantivos, p.e., %\n",
    "    text = list(filter(lambda a: a != '', text))\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neanderthal',\n",
       " 'genome',\n",
       " 'denisovan',\n",
       " 'genome',\n",
       " 'several',\n",
       " 'early',\n",
       " 'modern',\n",
       " 'human',\n",
       " 'genome',\n",
       " 'eurasia',\n",
       " 'archaic',\n",
       " 'hominin',\n",
       " 'mark',\n",
       " 'genome',\n",
       " 'modern',\n",
       " 'human',\n",
       " 'present',\n",
       " 'day',\n",
       " 'individual',\n",
       " 'eurasia',\n",
       " '∼2',\n",
       " 'genome',\n",
       " 'neanderthals',\n",
       " 'individual',\n",
       " 'oceania',\n",
       " 'genome',\n",
       " 'denisovans',\n",
       " 'suggestive',\n",
       " 'evidence',\n",
       " 'unidentified',\n",
       " 'hominin',\n",
       " 'specie',\n",
       " 'africa',\n",
       " 'functional',\n",
       " 'phenotypic',\n",
       " 'evolutionary',\n",
       " 'consequence',\n",
       " 'archaic',\n",
       " 'admixture',\n",
       " 'necessary',\n",
       " 'specific',\n",
       " 'haplotype',\n",
       " 'allele',\n",
       " 'archaic',\n",
       " 'hominin',\n",
       " 'ancestor',\n",
       " 'approach',\n",
       " 'introgressed',\n",
       " 'haplotype',\n",
       " 'method',\n",
       " 'reference',\n",
       " 'archaic',\n",
       " 'hominin',\n",
       " 'genome',\n",
       " 'sequence',\n",
       " 'reference',\n",
       " 'free',\n",
       " 'method',\n",
       " 'information',\n",
       " 'example',\n",
       " 'former',\n",
       " 'category',\n",
       " 'method',\n",
       " 'sankararaman',\n",
       " 'et',\n",
       " 'al',\n",
       " 'haplotype',\n",
       " 'modern',\n",
       " 'human',\n",
       " 'haplotype',\n",
       " 'reference',\n",
       " 'archaic',\n",
       " 'sequence',\n",
       " 'latter',\n",
       " 'category',\n",
       " 'method',\n",
       " 's∗',\n",
       " 'statistic',\n",
       " 'mutational',\n",
       " 'signature',\n",
       " 'ancient',\n",
       " 'admixture',\n",
       " 'leaf',\n",
       " 'genome',\n",
       " 'present',\n",
       " 'day',\n",
       " 'human',\n",
       " 's∗',\n",
       " 'approach',\n",
       " 'powerful',\n",
       " 'introgressed',\n",
       " 'haplotype',\n",
       " 'absence',\n",
       " 'archaic',\n",
       " 'reference',\n",
       " 'genome',\n",
       " 'unusual',\n",
       " 'mutational',\n",
       " 'characteristic',\n",
       " 'introgressed',\n",
       " 'haplotype',\n",
       " 'long',\n",
       " 'divergence',\n",
       " 'time',\n",
       " 'neanderthals',\n",
       " 'modern',\n",
       " 'human',\n",
       " 'neanderthals',\n",
       " 'many',\n",
       " 'allele',\n",
       " 'specific',\n",
       " 'lineage',\n",
       " 'allele',\n",
       " 'present',\n",
       " 'introgressed',\n",
       " 'haplotype',\n",
       " 'absent',\n",
       " 'rare',\n",
       " 'african',\n",
       " 'genome',\n",
       " 'recent',\n",
       " 'timing',\n",
       " 'admixture',\n",
       " 'introgressed',\n",
       " 'haplotype',\n",
       " 'recombination',\n",
       " 'distance',\n",
       " 'kb',\n",
       " 'average',\n",
       " 'high',\n",
       " 'level',\n",
       " 'linkage',\n",
       " 'disequilibrium',\n",
       " 'neanderthal',\n",
       " 'specific',\n",
       " 'allele',\n",
       " 'african',\n",
       " 'human',\n",
       " 'genome',\n",
       " 'study',\n",
       " 's∗like',\n",
       " 'method',\n",
       " 'power',\n",
       " 'suitable',\n",
       " 'large',\n",
       " 'scale',\n",
       " 'genome',\n",
       " 'wide',\n",
       " 'datum',\n",
       " 'method',\n",
       " 'large',\n",
       " 'set',\n",
       " 'datum',\n",
       " 'eurasia',\n",
       " 'oceania',\n",
       " 'putative',\n",
       " 'archaic',\n",
       " 'specific',\n",
       " 'allele',\n",
       " 'rate',\n",
       " 'allele',\n",
       " 'archaic',\n",
       " 'genome',\n",
       " 'role',\n",
       " 'gene',\n",
       " 'allele',\n",
       " 'insight',\n",
       " 'history',\n",
       " 'admixture',\n",
       " 'event',\n",
       " 'impact',\n",
       " 'modern',\n",
       " 'human',\n",
       " 'genome']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text='Sequencing the Neanderthal genome (Green et al., 2010, Prüfer et al., 2014), the Denisovan genome (Reich et al., 2010), and several early modern human genomes from Eurasia (Fu et al., 2014, Fu et al., 2015) has confirmed that archaic hominins left their mark in the genomes of modern humans (Plagnol and Wall, 2006, Sankararaman et al., 2014, Vernot and Akey, 2014, Vernot et al., 2016). Present-day individuals in Eurasia inherited ∼2% of their genome from Neanderthals (Green et al., 2010), and individuals from Oceania inherited ∼5% of their genome from Denisovans (Reich et al., 2010). Suggestive evidence indicates that admixture from other unidentified hominin species occurred in Africa (Hammer et al., 2011, Hsieh et al., 2016, Lachance et al., 2012, Plagnol and Wall, 2006, Wall et al., 2009). To understand the functional, phenotypic, and evolutionary consequences of archaic admixture, it is necessary to identify the specific haplotypes and alleles that were inherited from archaic hominin ancestors (Huerta-Sánchez et al., 2014, Juric et al., 2016, Sankararaman et al., 2014, Simonti et al., 2016, Vernot and Akey, 2014). Approaches to identifying introgressed haplotypes include methods that specifically incorporate reference archaic hominin genome sequences and reference-free methods that do not utilize such information. An example of the former category is the method of Sankararaman et al. (2014), which identifies archaic haplotypes by comparing modern human haplotypes to a reference archaic sequence. The latter category of methods include the S∗ statistic (Plagnol and Wall, 2006), which searches for the mutational signature that ancient admixture leaves in the genomes of present-day humans. The S∗ approach is powerful for finding introgressed haplotypes in the absence of an archaic reference genome because it leverages the unusual mutational characteristics of introgressed haplotypes. Because of the long divergence time between Neanderthals and modern humans, Neanderthals carry many alleles that are specific to their lineage. Such alleles are present on introgressed haplotypes but are absent or rare in African genomes. Further, based on the recent timing of admixture, introgressed haplotypes are expected to be maintained without recombination over distances of approximately 50 kb on average (Sankararaman et al., 2012), resulting in high levels of linkage disequilibrium (LD) between Neanderthal-specific alleles in non-African human genomes. In this study, we develop an S∗-like method that has increased power and is suitable for large-scale genome-wide data. We apply the method to large sets of sequenced data from Eurasia and Oceania and identify putative archaic-specific alleles. We examine the rate at which these alleles match the sequenced archaic genomes and the role of the genes containing these alleles, to obtain insights into the history of the admixture events and their impact on modern human genomes.'\n",
    "clean(text,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) grafo de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K es el largo de la ventana\n",
    "# filter_nouns_adj indica el tipo de filtrado\n",
    "# digraph indica el tipo de grafo- True = dirigido, False = no dirigido\n",
    "def graph_weighted(text,K,filter_nouns_adj,digraph):\n",
    "    text=clean(text,filter_nouns_adj)\n",
    "    unique_words=list(set(text))\n",
    "    if digraph==True: ## grafo dirigido o no dirigido\n",
    "        G=nx.DiGraph()\n",
    "    else:\n",
    "        G=nx.Graph()\n",
    "    for word in unique_words:\n",
    "        G.add_node(word)\n",
    "    for word in unique_words: ## recorremos el texto y encontramos los indices de todas las aparicions de word (index_word)\n",
    "        index_word=[index for index, value in enumerate(text) if value == word]\n",
    "        ## ahora buscamos las palabras vecinas en una ventana de largo K (hacia adelante)\n",
    "        for index in index_word:\n",
    "            for k in range(1,K+1):\n",
    "                if index+k in range(len(text)):\n",
    "                    if G.has_edge(text[index],text[index+k])==False:\n",
    "                        G.add_edge(text[index],text[index+k],weight=1)\n",
    "                    else:\n",
    "                        x=G[text[index]][text[index+k]]['weight']\n",
    "                        G[text[index]][text[index+k]]['weight']=x+1\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7fb92a57b5f8>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_weighted(text,4,True,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) keywords segun pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K es el largo de la ventana\n",
    "# filter_nouns_adj indica el tipo de filtrado\n",
    "# number_keywords indica el numero de keywords\n",
    "# digraph indica si queremos un grafo dirigido (True) o no dirigido (False)\n",
    "def keywords_pagerank(text,number_keywords,filter_nouns_adj,K,digraph):\n",
    "    n=len(clean(text,filter_nouns_adj))\n",
    "    G=graph_weighted(text,K,filter_nouns_adj,digraph)\n",
    "    keywords=nx.pagerank(G, alpha=0.85, weight='weight')\n",
    "    if n<number_keywords: ## en el caso de que el texto sea muy corto (incluso menor al numero de keywords)\n",
    "        number_keywords=n\n",
    "    return list(list(zip(*sorted(keywords.items(), key=operator.itemgetter(1),reverse=True)))[0][:number_keywords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['genome',\n",
       " 'archaic',\n",
       " 'haplotype',\n",
       " 'allele',\n",
       " 'human',\n",
       " 'method',\n",
       " 'modern',\n",
       " 'introgressed',\n",
       " 'admixture',\n",
       " 'specific']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_pagerank(text,10,True,4,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) keywords segun main core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K es el largo de la ventana\n",
    "# filter_nouns_adj indica el tipo de filtrado\n",
    "# digraph es el tipo de grafo - True = grafo dirigido, False = grafo no dirigido\n",
    "# en esta funcion, no es necesario indicar el numero de keywords. Fijamos un maximo de 10 (esto puede ser un parametro)\n",
    "def keywords_kcore(text,filter_nouns_adj,K,digraph):\n",
    "    G=graph_weighted(text,K,filter_nouns_adj,digraph)\n",
    "    G.remove_edges_from(nx.selfloop_edges(G)) ## evitamos ciclos para evitar que Networkx entregue un error\n",
    "    main_core_nodes=list(nx.k_core(G).nodes())\n",
    "    n=len(main_core_nodes)\n",
    "    if n>10:\n",
    "        return main_core_nodes[:10]\n",
    "    else:\n",
    "        return main_core_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['genome',\n",
       " 'method',\n",
       " 'archaic',\n",
       " 'present',\n",
       " 'neanderthals',\n",
       " 'human',\n",
       " 'introgressed',\n",
       " 'reference',\n",
       " 'hominin',\n",
       " 'modern']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_kcore(text,True,4,True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) 2-gramas de keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_keywords(text,filter_nouns_adj,K,digraph):\n",
    "    bigram=[]\n",
    "    G=graph_weighted(text,K,filter_nouns_adj,digraph)\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    main_core=nx.k_core(G) ## subgrafo del grafo de co-ocurrencia\n",
    "    list_edges=main_core.edges(data=True) ## lista de posibles bigramas, las aristas del main_core\n",
    "    destruct_edges=list(zip(*list_edges))\n",
    "    x=destruct_edges[0]\n",
    "    y=destruct_edges[1]\n",
    "    w=destruct_edges[2]\n",
    "    text=clean(text,True) ## lista de palabras (que dependen de True o False para ver que clase incluyen)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        key_1=x[i]\n",
    "        key_2=y[i]\n",
    "        exists = (key_1,key_2) in zip(text, text[1:]) ## miramos si la arista aparece en el texto como palabras adyacentes\n",
    "        if exists==True:\n",
    "            bigram+=[(key_1+' '+key_2,w[i]['weight'])]\n",
    "    BIGRAM=list(zip(*sorted(bigram, key=lambda tup: tup[1],reverse=True)))[0] ## ordenamos segun frecuencia del bigrama\n",
    "    n=len(BIGRAM)\n",
    "    if n>10: ## tambien fijamos en 10 el numero maximo de bigramas (puede ser un parametro)\n",
    "        return list(BIGRAM[:10])\n",
    "    else:\n",
    "        return list(BIGRAM)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['introgressed haplotype',\n",
       " 'modern human',\n",
       " 'specific allele',\n",
       " 'archaic genome',\n",
       " 'haplotype reference',\n",
       " 'archaic hominin',\n",
       " 'human genome',\n",
       " 'allele archaic',\n",
       " 'genome modern',\n",
       " 'genome present']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_keywords(text,True,4,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
